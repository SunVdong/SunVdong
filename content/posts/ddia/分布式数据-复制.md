---
title: "分布式数据-复制"
date: "2024-04-15T18:00:06+08:00"
draft: true
author: "vdong"
categories:
  - "生活"
  - "技术"
tags:
  - "日常"
  - "折腾"
typora-root-url: ..\..\..\static
---

复制的原因：

- 使数据和用户在地理位置上更近（降低延迟）
- 使系统即使一部分故障，也能正常工作（提高可用性）
- 伸缩可接受读请求的机器数量（提高读取吞吐量）

复制的困难：在于处理数据的变更。变更复制算法：**单主（singer leader ，单领导者）**，**多主（multi leader，多领导者）**，**无主（leaderless ，无领队者）**。

复制时需要权衡的问题：1. 同步还是异步？2. 如何处理失败的副本？...

## 领导者和追随者

存储了数据库拷贝的每个节点被称为 **副本（replica）**。

每一次向数据库的写入操作都需要传播到所有副本上，否则副本就会包含不一样的数据。解决方案：基于领导者的复制，主从。原理：

1. 其中一个副本被指定为 **领导者（leader）**，也称为 **主库（master|primary）** 。当客户端要向数据库写入时，它必须将请求发送给该 **领导者**，其会将新数据写入其本地存储。
2. 其他副本被称为 **追随者（followers）**，亦称为 **只读副本（read replicas）**、**从库（slaves）**、**备库（ secondaries）** 或 **热备（hot-standby）**。每当领导者将新数据写入本地存储时，它也会将数据变更发送给所有的追随者，称之为 **复制日志（replication log）** 或 **变更流（change stream）**。每个跟随者从领导者拉取日志，并相应更新其本地数据库副本，方法是按照与领导者相同的处理顺序来进行所有写入。
3. 当客户想要从数据库中读取数据时，它可以向领导者或任一追随者进行查询。但只有领导者才能接受写入操作（从客户端的角度来看从库都是只读的）。

这种复制模式是很多关系型数据库的内置功能，也被用于一些非关系数据库（如：MongoDB、RethinkDB 和 Espresso），甚至它不仅限于数据库：Kafka、RabbitMQ 等分布式消息代理也使用它。某些网络文件系统，如 DRBD 这样的块复制设备也类似。

### 同步复制or异步复制

![img](/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE-%E5%A4%8D%E5%88%B6/fig5-2.png)

Follower1 是同步复制，主库等待从库确认后，才向用户报告写入成功。

Follower2 是异步复制，主库不等待从库的响应。

通常从库的复制是很快的：大多数数据库能在不到1秒中完成同步。但是，这是没有保证的。有些情况从库可能落后主库几分钟，如：从库正在从失败中恢复；系统正在最大负载附近工作；或者节点间的网络问题。

同步复制的优点：副本被保障拥有领导者最新且一致的数据，当领导者挂了，副本可以直接上。缺点：如果从库（crash 或者网络问题等）没有响应，主库就无法处理写入操作。

因此，将所有从库都设置为同步的是不切实际的：任何一个节点的中断都会导致整个系统停滞不前。实际上，如果在数据库上启用同步复制，通常意味着其中 **一个** 从库是同步的，而其他的从库则是异步的。如果该同步从库变得不可用或缓慢，则将一个异步从库改为同步运行。这保证你至少在两个节点上拥有最新的数据副本：主库和同步从库。 这种配置有时也被称为 **半同步（semi-synchronous）**。

异步复制缺点：主库失效且不可恢复，未复制给从库的写入将丢失。优点：即使所有从库都落后了，主库也可以继续处理写入。弱的持久化。

### 设置新从库

数据不断变化，简单复制是不行的（复制过程中也可能有数据变化），如果先锁定数据库再复制，违背了高可用性的目标，所以复制过程通常如下：

1. 在某个时刻获取主库一致性快照。如：mysql 的 innobackupex 和 XtraBackup。
2. 将快照复制到新的从库节点。
3. 从库连接主库，拉取快照之后发生的数据变更。前提要求是快照和主库复制日志中位置精确对应。这个位置有不同的名称，如 PostgreSQL 中叫 **日志序列号（log sequence nubmer，LSN）**， MySQL 中叫 **二进制日志坐标（binlog coordinates）**。
4. 当从库处理完快照之后积累的数据变更，从库 **赶上（caught up）**了主库。

### 处理节点宕机

任何节点都可能宕机，例如意外故障，计划内的维护。我们的目标是即使个别节点失效，也能保持整个系统的运行，尽可能控制停机带来的影响。基于领导者的复制是怎么做到高可用的呢？

#### 从库失效：追赶恢复

在从库的本地磁盘中，每个从库都保存着它从主库收到的数据变更日志。如果一个从库崩溃并重启，或者主库和从库的网络临时中断，从库可以很容易的恢复：它从日志中可以知道故障发生前，已经处理的最后一个事务。因此，从库连上主库，请求从库断开期间的所有数据变更。

#### 主库失效：故障切换

主库失效处理起来非常棘手： 其中一个从库会被提升为主库，需要重新配置客户端，以将其写操作发送给新的主库，其余从库需要开始拉取新主库的数据变更。这个过程被称为 **故障切换（failover）**。

故障切换可以手动执行，也可以自动执行。自动执行的步骤通常如下：

1. 确认主库失效。通常采用超时来确认失效，节点频繁的互相来回传递消息。如果一个节点一段时间（如30s）内没有响应，则认为它挂了。
2. 选择一个新的主库。这可以通过选举过程（主库由剩余副本以多数选举产生）来完成，或者可以由选定的 **控制器节点（controller node）** 来指定新的主库。主库的最佳候选人通常是拥有旧主库最新数据副本的从库（以最小化数据损失）。涉及 共识 问题。
3. 重新配置系统以启用新的从库。客户端现在需要将它们的写入请求发送给新的主库（请求路由）。如果旧主库恢复，可能仍然认为自己是主库，而没有意识到其他副本眼看让他失去来领导权。系统需要确保旧的主库，意识到新主库的存在，并成为一个从库。

故障切换有很多地方容易出错：

1.  如果使用异步复制，则新主库可能没有收到老主库宕机前的写入操作。选出新主库后，如果老的主库重新加入集群，新主库在此期间可能收到冲突的写入，这些写入该怎么处理呢？常见的解决方案是，简单丢弃老主库未复制的写入，这可能打破客户对数据持久化的期望。
2. 如果数据库需要和其他外部存储相协调，丢弃写入内容是极其危险的操作。例如在 GitHub 的一场事故中，一个过时的 MySQL 从库被提升为主库。数据库使用自增 ID 作为主键，因为新主库的计数器落后于老主库的计数器，所以新主库重新分配了一些已经被老主库分配掉的 ID 作为主键。这些主键也在 Redis 中使用，主键重用使得 MySQL 和 Redis 中的数据产生不一致，最后导致一些私有数据泄漏到错误的用户手中。
3. 发生某些故障时，可能两个节点都认为自己是主库，称为 **脑裂（split brain）**： 两个主库都可以接受写操作，却没有冲突解决机制，那么数据就会丢失或损坏，某些系统采取来安全防范措施： 当检测到两个主库节点同时存在时，会关闭其中一个节点（ 这种机制叫 **屏障 fencing**，或者充满感情的术语是 ： **爆彼之头 Shoot The Other Node In The Head， STONITH** ），但是粗糙的设计可能导致两个节点都被关闭。
4. 主库被宣告死亡的超时应该怎么设置呢？主库失效的情况下，超时时间越长，则意味着恢复的时间也越长。如果超时时间设置的太短，则可能会出现不必要的切换。例如，临时的负载峰值可能导致节点的响应时间增加到超出超时时间，或者网络故障也可能导致数据包延迟。如果系统已经处于高负载或网络问题的困扰之中，那么不必要的故障切换可能会让情况变得更糟糕。

这些问题没有简单的解决方案。因此，即使软件支持自动故障切换，不少运维团队还是更愿意手动执行故障切换。

节点故障、不可靠的网络、对副本一致性、持久性、可用性和延迟的权衡，这些问题实际上是分布式系统中的基本问题。

### 复制日志的实现

#### 基于语句的复制

最简单的场景下，主库会记录下它执行的每个写请求（**语句**，statement），并将该语句日志发送给从库。对关系型数据库而言，每个 INSERT，UPDATE，DELETE 语句都被发送到从库，从库解析并执行这些语句，就像他是从客户端收到的一样。

这种方式听起来很合理，但是还是有一些场景，可以导致这种复制方式出现问题。

1. 语句中包含不确定的函数，如 `NOW()` 、 `RAND()` 等，每个副本都会产生不同的值。
2. 如果一个语句使用自增序列，或者依赖数据库中存在的数据（如 UPDATE ... WHERE <some condition>）, 在每个副本中，这些语句必须按照相同的顺序执行，否则就可能产生不同的效果。这在有多个并发事务时，会是一种限制。
3. 有副作用的语句（如： trigger，存储过程，用户定义的函数 ）可能在每个副本上产生不同的副作用，除非副作用是确定的。

当然这些问题可以绕开，例如，当主库语句日志记录时，替换不确定的函数调用 为 函数调用的返回值，这样每个从库将得到相同的值。但是，由于边界情况太多了，通常选择其他的复制方法。

#### 预写入日志传输 （Write-ahead log）

数据的存储和检索中，存储引擎的写操作通常都是追加到日志中：

- 对于日志结构的存储引擎（SSTable 和 LSM tree），日志是主要的存储位置，日志段在后台被压实和垃圾回收。
- 对于覆写单个磁盘块的 B-tree ，每次修改都会先写入  **预写式日志（Write Ahead Log, WAL）** ，以便崩溃后索引可以恢复到一个一致的状态。

在任一情况下，日志都是一个只追加的字节序列，包含了对数据库的所有写操作。我们可以使用完全相同的日志来在另一个节点上构建一个副本：主库除了将日志写入磁盘外，还将其通过网络发送给其从库。

追随者处理这些日志，可以构建一个与主库一模一样的数据结构拷贝。

这种复制方法在 PostgreSQL 和 Oracle 等产品中被使用到，缺点，日志记录数据非常底层： WAL 包含哪些磁盘块中的哪些字节发生了更改。这使复制与存储引擎紧密耦合。如果数据库将其存储格式从一个版本更改为另一个版本，通常不可能在主库和从库上运行不同版本的数据库软件。

看上去这可能只是一个小的实现细节，但却可能产生巨大的操作影响。如果复制协议允许从库使用比主库更新的软件版本，则可以先升级从库，然后执行故障切换，使升级后的节点之一成为新的主库，从而允许数据库软件的零停机升级。如果复制协议不允许版本不匹配（传输 WAL 经常出现这种情况），则此类升级需要停机。

#### 逻辑日志复制（基于行）

复制时使用和存储引擎不一样的格式，这样可以是复制日志从存储引擎中解耦出来。这种类型的复制日志被称为 **逻辑日志**。

关系型数据库的逻辑日志通常是以行为颗粒度描述对数据库表的写入记录序列：

- 对于插入的行，日志包含所有新值。
- 对于删除的行，日志包含足够的信息来唯一标识被删除的行。通常是主键，但是如果表上没有主键，则需要记录所有列的旧值。
- 对于更新的行，日志包含足够的信息来唯一标识更新的行，以及所有列的新值（或至少所有已更改的列的新值）。

修改多行的事务会生成多个这样的日志记录，后边跟着一条记录，指出事务已经提交。MySQL的二进制日志（当配置基于行的复制时）使用这种方法。

由于逻辑日志和存储引擎内部分离，因此可以更容易的保持向后兼容，从而是领导者和跟随者可以运行不同的数据库软件版本，甚至使用不同送存储引擎。

对于外部应用程序来说，逻辑日志格式也很容易解析。如果要将数据库的内容发送至外部系统（如用于离线分析或建立自定义索引和缓存的数据仓库），这种特性将很有用。这种技术称为 **数据变更捕获**。

#### 基于触发器的复制

以上复制都是数据库系统实现的，不涉及应用代码，但是有时，你可能希望更灵活，比如你希望复制一个数据子集，或者从一种数据库复制到另一种数据库，或者你需要自定义冲突解决的逻辑，则可能需要将复制移动到应用程序层。

一些工具，如 Oracle Golden Gate 可以通过读取数据库日志，使得应用程序可以使用数据。 另一种方法是使用关系数据库自带的功能： 触发器和存储过程。

触发器允许您注册在数据库系统中发生数据更改（写入事务）时自动执行的自定义应用程序代码。触发器有机会将更改记录到一个单独的表中，使用外部程序读取这个表，再加上任何业务逻辑处理，会后将数据变更复制到另一个系统去。例如，Databus for Oracle 和 Bucardo for Postgres 就是这样工作的。

基于触发器的复制通常比其他复制方法具有更高的开销，并且比数据库的内置复制更容易出错，也有很多限制。然而由于其灵活性，仍然是很有用的。


## 复制延迟问题

对于读多写少的场景，读伸缩（read-scaling）的体系结构，通常使用异步复制，将读请求分散到从库上，减少主库的负载。

不幸的是，当应用程序从异步从库读取时，如果从库落后，它可能会看到过时的信息。这会导致数据库中出现明显的不一致：同时对主库和从库执行相同的查询，可能得到不同的结果，因为并非所有的写入都反映在从库中。这种不一致只是一个暂时的状态 —— 如果停止写入数据库并等待一段时间，从库最终会赶上并与主库保持一致。出于这个原因，这种效应被称为 最终一致性（eventual consistency）。

最终一致性的 “最终” 是模糊化的，复制延迟（replication lag），反应了写入到主库和在从库中反应之间的延迟，可能仅仅是几分之一秒，在实践中并不显眼。但如果系统在接近极限的情况下运行，或网络中存在问题时，延迟可以轻而易举地超过几秒，甚至达到几分钟。

复制延迟可能造成一些问题

### 读己之写

如下：用户在写入后马上就查看数据，则新数据可能尚未到达副本。对用户而言，看起来好像是刚提交的数据丢失了。

![img](/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE-%E5%A4%8D%E5%88%B6/fig5-3.png)

这种情况下，需要 **写后读一致性（read-after-write consistency）** ，也叫 **读己之写一致性（read）**。如果用户重新加载页面，他们总会看到他们自己提交的任何更新。它不会对其他用户的写入做出承诺：其他用户的更新可能稍等才会看到。它保证用户自己的输入已被正确保存。

基于领导者的复制怎么实现写后读一致性呢：

- 对于用户 **可能修改过** 的内容，总是从主库读取；这要求，需要有办法不通过实际查询就可以知道用户是否修改了某些东西。例如：社交网络的个人信息只能本人维护。因此，总是从主库读取用户自己的个人信息，如果读取其他用户的就去从库。
- 如果应用中的大部分内容都可能被用户自己编辑，那上边的方法就失效了，因为大部分内容必须从主库读取（读伸缩就没有效果了）。这种情况下需要别的标准来决定是否从主库读取。如，跟踪上次更新时间，在上次更新时间一分钟以内，从主库读。还可以监控从库的复制延迟，防止向延迟超过一分钟的从库发出查询。
- 客户端记录最近一次写入的时间戳，系统需要确保从库在处理该用户读取请求时，该时间戳前的变更已经被应用到了该从库中。如果当前从库不够新，在可以从另一个从库中获取，或者等待主库赶上来。这里的时间戳可以是逻辑时间戳（表示写入顺序的东西，如日志序列号），也可以是实际系统时间（这时，时钟同步变得至关重要）。
- 如果你的副本分布在多个数据中心（为了地理上接近用户或者高可用目的），还会有额外的复杂性：任何需要主库提供服务的请求，都需要路由到包含该主库的数据中心。

另一种复杂的情况，同一个用户从多个设备（如，桌面浏览器和mobile app）上请求服务。这时需要跨设备的写后一致性：如果用户在一个设备上输入了一些信息，然后在另一个设备上查看，则应该看到他们刚输入的信息。

这种情况下，需要考虑一些问题：

- 记住用户的更新时间戳变得困难，因为一个设备上运行的程序不知道另一个设备上发生了什么，需要对这些元数据进行中心化存储。
- 如果副本分布在不同的数据中心，很难保证来自不同设备的的连接路由到同一个数据中心。（如，台式计算机使用的是家庭宽带，而移动设备使用的是蜂窝数据，设备的网络路由可能完全不同）。如果你的请求需要读取主库，可能首先需要把来自该用户所有设备的请求都路由到同一个数据中心。

### 单调读

从从库中异步读取时，可能发生的第二种异常情况是，用户可能遇到时光倒流（moving backward in time）。

如果用户从不同从库进行多次读取，就可能发生这种情况。如下：

![img](/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE-%E5%A4%8D%E5%88%B6/fig5-4.png)

用户首先从新副本读取，然后从旧副本读取。时间看上去回退了。为了防止这种异常，我们需要单调的读取。

**单调读（monotonic reads）**可以保证这种异常不会发生，这个是比 **强一致性（strong consistency）** 更弱，比 **最终一致性（eventual consistency）** 更强的保证。你可能读取到旧值；单调读意味着，如果一个用户按顺序进行多次读取，不会出现时间倒流的情况，也就是说，如果已经读到了数据，后续再读到的数据都是比之前的读到的数据更新。

单调读的一种实现方式是确保某个用户总是从同一个副本读取（不同的用户可以从不同的副本）。例如，基于用户 ID 散列来选择副本，而不是随机选择副本。但，如果该副本出现故障，用户的查询需要重新路由到另一个副本。

### 一致前缀读

第三种复制延迟异常的例子是违反了因果律。

现在，想象第三个人正在通过从库来听一个对话。 Cake 夫人回答的内容是从一个延迟很低的从库读取的，但 Poons 先生所问的问题，从库的延迟要大的多（如下图）。于是，这个观察者会先听到问题的答案，然后才听到问题。

![img](/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE-%E5%A4%8D%E5%88%B6/fig5-5.png)

为防止这种异常，需要另一种类型的保证：**一致前缀读（consistent prefix reads）**。 即：如果一系列写入是按某个顺序发生的，那么任何人在读取时，也需要以相同的顺序读取。

这是 **分区（partitioned）** 或 **分片（sharded）** 数据库中的一个特殊问题。如果数据库总是以相同的顺序应用写入，而读取总是看到一致的前缀，那么这种异常不会发生。但是在许多分布式数据库中，不同的分区独立运行，因此不存在 **全局的写入顺序**：当用户从数据库中读取数据时，可能会看到数据库的某些部分处于较旧的状态，而某些则处于较新的状态。

一种解决方案是，确保任何因果相关的写入都写入相同的分区，但在一些应用中可能无法高效地完成这种操作。还有一些显式跟踪因果依赖关系的算法，待续。

### 复制延迟的解决方案





















