+++
title = "分布式数据-复制"
date = 2024-04-15T18:00:06+08:00
draft = false
author = 'vdong'
categories = ['生活', '技术']
tags = ['日常', '折腾']
typora-root-url = "..\\..\\..\\static"

+++

复制的原因：

- 使数据和用户在地理位置上更近（降低延迟）
- 使系统即使一部分故障，也能正常工作（提高可用性）
- 伸缩可接受读请求的机器数量（提高读取吞吐量）

复制的困难：在于处理数据的变更。变更复制算法：**单主（singer leader ，单领导者）**，**多主（multi leader，多领导者）**，**无主（leaderless ，无领队者）**。

复制时需要权衡的问题：1. 同步还是异步？2. 如何处理失败的副本？...

## 领导者和追随者

存储了数据库拷贝的每个节点被称为 **副本（replica）**。

每一次向数据库的写入操作都需要传播到所有副本上，否则副本就会包含不一样的数据。解决方案：基于领导者的复制，主从。原理：

1. 其中一个副本被指定为 **领导者（leader）**，也称为 **主库（master|primary）** 。当客户端要向数据库写入时，它必须将请求发送给该 **领导者**，其会将新数据写入其本地存储。
2. 其他副本被称为 **追随者（followers）**，亦称为 **只读副本（read replicas）**、**从库（slaves）**、**备库（ secondaries）** 或 **热备（hot-standby）**。每当领导者将新数据写入本地存储时，它也会将数据变更发送给所有的追随者，称之为 **复制日志（replication log）** 或 **变更流（change stream）**。每个跟随者从领导者拉取日志，并相应更新其本地数据库副本，方法是按照与领导者相同的处理顺序来进行所有写入。
3. 当客户想要从数据库中读取数据时，它可以向领导者或任一追随者进行查询。但只有领导者才能接受写入操作（从客户端的角度来看从库都是只读的）。

这种复制模式是很多关系型数据库的内置功能，也被用于一些非关系数据库（如：MongoDB、RethinkDB 和 Espresso），甚至它不仅限于数据库：Kafka、RabbitMQ 等分布式消息代理也使用它。某些网络文件系统，如 DRBD 这样的块复制设备也类似。

### 同步复制or异步复制

![img](/imgs/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE-%E5%A4%8D%E5%88%B6/fig5-2.png)

Follower1 是同步复制，主库等待从库确认后，才向用户报告写入成功。

Follower2 是异步复制，主库不等待从库的响应。

通常从库的复制是很快的：大多数数据库能在不到1秒中完成同步。但是，这是没有保证的。有些情况从库可能落后主库几分钟，如：从库正在从失败中恢复；系统正在最大负载附近工作；或者节点间的网络问题。

同步复制的优点：副本被保障拥有领导者最新且一致的数据，当领导者挂了，副本可以直接上。缺点：如果从库（crash 或者网络问题等）没有响应，主库就无法处理写入操作。

因此，将所有从库都设置为同步的是不切实际的：任何一个节点的中断都会导致整个系统停滞不前。实际上，如果在数据库上启用同步复制，通常意味着其中 **一个** 从库是同步的，而其他的从库则是异步的。如果该同步从库变得不可用或缓慢，则将一个异步从库改为同步运行。这保证你至少在两个节点上拥有最新的数据副本：主库和同步从库。 这种配置有时也被称为 **半同步（semi-synchronous）**。

异步复制缺点：主库失效且不可恢复，未复制给从库的写入将丢失。优点：即使所有从库都落后了，主库也可以继续处理写入。弱的持久化。

### 设置新从库

数据不断变化，简单复制是不行的（复制过程中也可能有数据变化），如果先锁定数据库再复制，违背了高可用性的目标，所以复制过程通常如下：

1. 在某个时刻获取主库一致性快照。如：mysql 的 innobackupex 和 XtraBackup。
2. 将快照复制到新的从库节点。
3. 从库连接主库，拉取快照之后发生的数据变更。前提要求是快照和主库复制日志中位置精确对应。这个位置有不同的名称，如 PostgreSQL 中叫 **日志序列号（log sequence nubmer，LSN）**， MySQL 中叫 **二进制日志坐标（binlog coordinates）**。
4. 当从库处理完快照之后积累的数据变更，从库 **赶上（caught up）**了主库。

### 处理节点宕机

任何节点都可能宕机，例如意外故障，计划内的维护。我们的目标是即使个别节点失效，也能保持整个系统的运行，尽可能控制停机带来的影响。基于领导者的复制是怎么做到高可用的呢？

#### 从库失效：追赶恢复

在从库的本地磁盘中，每个从库都保存着它从主库收到的数据变更日志。如果一个从库崩溃并重启，或者主库和从库的网络临时中断，从库可以很容易的恢复：它从日志中可以知道故障发生前，已经处理的最后一个事务。因此，从库连上主库，请求从库断开期间的所有数据变更。

#### 主库失效：故障切换

主库失效处理起来非常棘手： 其中一个从库会被提升为主库，需要重新配置客户端，以将其写操作发送给新的主库，其余从库需要开始拉取新主库的数据变更。这个过程被称为 **故障切换（failover）**。

故障切换可以手动执行，也可以自动执行。自动执行的步骤通常如下：

1. 确认主库失效。通常采用超时来确认失效，节点频繁的互相来回传递消息。如果一个节点一段时间（如30s）内没有响应，则认为它挂了。
2. 选择一个新的主库。这可以通过选举过程（主库由剩余副本以多数选举产生）来完成，或者可以由选定的 **控制器节点（controller node）** 来指定新的主库。主库的最佳候选人通常是拥有旧主库最新数据副本的从库（以最小化数据损失）。涉及 共识 问题。
3. 重新配置系统以启用新的从库。客户端现在需要将它们的写入请求发送给新的主库（请求路由）。如果旧主库恢复，可能仍然认为自己是主库，而没有意识到其他副本眼看让他失去来领导权。系统需要确保旧的主库，意识到新主库的存在，并成为一个从库。

故障切换有很多地方容易出错：

1.  如果使用异步复制，则新主库可能没有收到老主库宕机前的写入操作。选出新主库后，如果老的主库重新加入集群，新主库在此期间可能收到冲突的写入，这些写入该怎么处理呢？常见的解决方案是，简单丢弃老主库未复制的写入，这可能打破客户对数据持久化的期望。
2. 如果数据库需要和其他外部存储相协调，丢弃写入内容是极其危险的操作。例如在 GitHub 的一场事故中，一个过时的 MySQL 从库被提升为主库。数据库使用自增 ID 作为主键，因为新主库的计数器落后于老主库的计数器，所以新主库重新分配了一些已经被老主库分配掉的 ID 作为主键。这些主键也在 Redis 中使用，主键重用使得 MySQL 和 Redis 中的数据产生不一致，最后导致一些私有数据泄漏到错误的用户手中。
3. 发生某些故障时，可能两个节点都认为自己是主库，称为 **脑裂（split brain）**： 两个主库都可以接受写操作，却没有冲突解决机制，那么数据就会丢失或损坏，某些系统采取来安全防范措施： 当检测到两个主库节点同时存在时，会关闭其中一个节点（ 这种机制叫 **屏障 fencing**，或者充满感情的术语是 ： **爆彼之头 Shoot The Other Node In The Head， STONITH** ），但是粗糙的设计可能导致两个节点都被关闭。
4. 主库被宣告死亡的超时应该怎么设置呢？主库失效的情况下，超时时间越长，则意味着恢复的时间也越长。如果超时时间设置的太短，则可能会出现不必要的切换。例如，临时的负载峰值可能导致节点的响应时间增加到超出超时时间，或者网络故障也可能导致数据包延迟。如果系统已经处于高负载或网络问题的困扰之中，那么不必要的故障切换可能会让情况变得更糟糕。

这些问题没有简单的解决方案。因此，即使软件支持自动故障切换，不少运维团队还是更愿意手动执行故障切换。

节点故障、不可靠的网络、对副本一致性、持久性、可用性和延迟的权衡，这些问题实际上是分布式系统中的基本问题。

### 复制日志的实现

#### 基于语句的复制

最简单的场景下，主库会记录下它执行的每个写请求（**语句**，statement），并将该语句日志发送给从库。对关系型数据库而言，每个 INSERT，UPDATE，DELETE 语句都被发送到从库，从库解析并执行这些语句，就像他是从客户端收到的一样。

这种方式听起来很合理，但是还是有一些场景，可以导致这种复制方式出现问题。

1. 语句中包含不确定的函数，如 `NOW()` 、 `RAND()` 等，每个副本都会产生不同的值。
2. 如果一个语句使用自增序列，或者依赖数据库中存在的数据（如 UPDATE ... WHERE <some condition>）, 在每个副本中，这些语句必须按照相同的顺序执行，否则就可能产生不同的效果。这在有多个并发事务时，会是一种限制。
3. 有副作用的语句（如： trigger，存储过程，用户定义的函数 ）可能在每个副本上产生不同的副作用，除非副作用是确定的。

当然这些问题可以绕开，例如，当主库语句日志记录时，替换不确定的函数调用 为 函数调用的返回值，这样每个从库将得到相同的值。但是，由于边界情况太多了，通常选择其他的复制方法。

#### 预写入日志传输 （Write-ahead log）

数据的存储和检索中，存储引擎的写操作通常都是追加到日志中：

- 对于日志结构的存储引擎（SSTable 和 LSM tree），日志是主要的存储位置，日志段在后台被压实和垃圾回收。
- 对于覆写单个磁盘块的 B-tree ，每次修改都会先写入  **预写式日志（Write Ahead Log, WAL）** ，以便崩溃后索引可以恢复到一个一致的状态。

在任一情况下，日志都是一个只追加的字节序列，包含了对数据库的所有写操作。我们可以使用完全相同的日志来在另一个节点上构建一个副本：主库除了将日志写入磁盘外，还将其通过网络发送给其从库。

追随者处理这些日志，可以构建一个与主库一模一样的数据结构拷贝。

这种复制方法在 PostgreSQL 和 Oracle 等产品中被使用到，缺点，日志记录数据非常底层： WAL 包含哪些磁盘块中的哪些字节发生了更改。这使复制与存储引擎紧密耦合。如果数据库将其存储格式从一个版本更改为另一个版本，通常不可能在主库和从库上运行不同版本的数据库软件。

看上去这可能只是一个小的实现细节，但却可能产生巨大的操作影响。如果复制协议允许从库使用比主库更新的软件版本，则可以先升级从库，然后执行故障切换，使升级后的节点之一成为新的主库，从而允许数据库软件的零停机升级。如果复制协议不允许版本不匹配（传输 WAL 经常出现这种情况），则此类升级需要停机。